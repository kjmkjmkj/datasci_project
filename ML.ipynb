{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#svm\n",
    "from sklearn.svm import SVC\n",
    "#rf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "df = pd.read_csv('dataset/total_preprocessed_featureselected.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack Name\n",
       "Benign Traffic              86525\n",
       "Recon Ping Sweep            47123\n",
       "Recon OS Scan               42173\n",
       "Recon Vulnerability Scan    39489\n",
       "Dictionary Brute Force      18151\n",
       "DoS SYN Flood               15243\n",
       "MITM ARP Spoofing           14768\n",
       "DoS UDP Flood                1848\n",
       "DoS DNS Flood                1702\n",
       "DoS ICMP Flood               1405\n",
       "Recon Host Discovery          424\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Attack Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y split\n",
    "X = df.drop(columns=['Attack Name'])\n",
    "y = df['Attack Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing 함수\n",
    "def preprocess(X, y):\n",
    "    # 문자열 레이블을 정수로 변환\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  # 문자열 -> 정수 변환\n",
    "\n",
    "    # Train/Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # SMOTE로 클래스 균형 조정\n",
    "    smote = SMOTE(random_state=0, sampling_strategy={\n",
    "        label_encoder.transform(['Recon Ping Sweep'])[0]: 60000,\n",
    "        label_encoder.transform(['Recon OS Scan'])[0]: 60000,\n",
    "        label_encoder.transform(['Recon Vulnerability Scan'])[0]: 50000,\n",
    "        label_encoder.transform(['Dictionary Brute Force'])[0]: 30000,\n",
    "        label_encoder.transform(['DoS SYN Flood'])[0]: 25000,\n",
    "        label_encoder.transform(['MITM ARP Spoofing'])[0]: 20000,\n",
    "        label_encoder.transform(['DoS UDP Flood'])[0]: 5000,\n",
    "        label_encoder.transform(['DoS DNS Flood'])[0]: 5000,\n",
    "        label_encoder.transform(['DoS ICMP Flood'])[0]: 4000,\n",
    "        label_encoder.transform(['Recon Host Discovery'])[0]: 2000\n",
    "    })\n",
    "\n",
    "    # Oversampling\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"Resampled Data Shape: {X_train_res.shape}, {y_train_res.shape}\")\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_res = scaler.fit_transform(X_train_res)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_res, X_train, X_test, y_train_res, y_train, y_test, label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Data Shape: (330213, 48), (330213,)\n"
     ]
    }
   ],
   "source": [
    "X_train_res, X_train, X_test, y_train_res, y_train, y_test,label_encoder=preprocess(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(X_train, y_train, X_test, y_test, label_encoder):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    # 모델 초기화 및 하이퍼파라미터 탐색\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_dist = {\n",
    "        'n_neighbors': range(5, 19),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "    random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 파라미터 출력\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "    # 예측\n",
    "    y_pred = random_search.predict(X_test)\n",
    "\n",
    "    # 라벨 복원\n",
    "    y_test_str = label_encoder.inverse_transform(y_test)  # 실제 라벨 복원\n",
    "    y_pred_str = label_encoder.inverse_transform(y_pred)  # 예측 라벨 복원\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_str, y_pred_str))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_str, y_pred_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model(X_train, y_train, X_test, y_test, label_encoder):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    # RandomForest 초기화 및 하이퍼파라미터 탐색 설정\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    param_dist = {\n",
    "        'n_estimators': range(100, 1000, 100),\n",
    "        'max_depth': range(10, 100, 10),\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    # RandomizedSearchCV로 하이퍼파라미터 최적화\n",
    "    random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 파라미터 출력\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "    # 테스트 데이터에 대한 예측\n",
    "    y_pred = random_search.predict(X_test)\n",
    "\n",
    "    # 라벨 복원 (정수 -> 문자열)\n",
    "    y_test_str = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_str = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # 평가 결과 출력\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_str, y_pred_str))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_str, y_pred_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def lgbm_model(X_train, y_train, X_test, y_test):\n",
    "    lgbm = LGBMClassifier(random_state=42)\n",
    "\n",
    "    param_dist = {\n",
    "        'n_estimators': range(100, 1000, 100),\n",
    "        'max_depth': range(10, 100, 10),\n",
    "        'learning_rate': range(0.001, 0.01, 0.001),\n",
    "        'num_leaves': range(10, 100, 10)\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(lgbm, param_distributions=param_dist, n_iter=10, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(random_search.best_params_)\n",
    "    # evaluation\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'weights': 'distance', 'n_neighbors': 16, 'metric': 'manhattan'}\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "          Benign Traffic       0.72      0.68      0.70     17312\n",
      "  Dictionary Brute Force       0.46      0.38      0.42      3603\n",
      "           DoS DNS Flood       0.03      0.13      0.04       326\n",
      "          DoS ICMP Flood       0.04      0.07      0.05       294\n",
      "           DoS SYN Flood       0.99      0.91      0.95      3096\n",
      "           DoS UDP Flood       0.03      0.17      0.05       341\n",
      "       MITM ARP Spoofing       0.69      0.51      0.59      2888\n",
      "    Recon Host Discovery       0.00      0.03      0.01        70\n",
      "           Recon OS Scan       0.48      0.27      0.34      8365\n",
      "        Recon Ping Sweep       0.49      0.61      0.54      9513\n",
      "Recon Vulnerability Scan       0.95      0.97      0.96      7963\n",
      "\n",
      "                accuracy                           0.62     53771\n",
      "               macro avg       0.44      0.43      0.42     53771\n",
      "            weighted avg       0.66      0.62      0.63     53771\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11769  1058  1210   300     9  1393   460   298   177   402   236]\n",
      " [ 1465  1382   124    74    10   161   106   100    33   102    46]\n",
      " [  153    36    42     8     5    41     6     5     7    12    11]\n",
      " [  157    27    18    20     2    32     7     6     7    14     4]\n",
      " [  140    34    20    12  2816    46     3     5     8     8     4]\n",
      " [  178    24    23     9     3    57     8    12     4    13    10]\n",
      " [  942   196    52    21     0   115  1466    28    14    32    22]\n",
      " [   38     6     4     2     0     8     1     2     1     5     3]\n",
      " [  445    82    45    24     0   106    14    34  2217  5375    23]\n",
      " [ 1053   151    84    36     6   177    25    70  2104  5772    35]\n",
      " [   97    22    15     2     1     9    17     6     7    30  7757]]\n"
     ]
    }
   ],
   "source": [
    "#증강 모델\n",
    "knn_model(X_train_res, y_train_res, X_test, y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rf_model(X_train_res, y_train_res, X_test, y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model(X_train_res, y_train_res, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공격 유형별로 분류하는 것은 어려움이 있을 것으로 판단, benign traffic과 아닌 것으로 나누기\n",
    "df['Attack Name'] = df['Attack Name'].apply(lambda x: 1 if x == 'Benign Traffic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attack Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_01 = df.drop(columns=['Attack Name'])\n",
    "y_01 = df['Attack Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train_01, X_test_01, y_train_01, y_test_01 = train_test_split(X_01, y_01, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_01 = scaler.fit_transform(X_train_01)\n",
    "X_test_01 = scaler.transform(X_test_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "knn_model(X_train_01, y_train_01, X_test_01, y_test_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf\n",
    "rf_model(X_train_01, y_train_01, X_test_01, y_test_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm\n",
    "lgbm_model(X_train_01, y_train_01, X_test_01, y_test_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
